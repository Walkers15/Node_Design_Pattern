---


---

<h1 id="장-스트림-코딩">5장 스트림 코딩</h1>
<p>스트림은 노드의 가장 중요한 컴포넌트이자 패턴중 하나이다.</p>
<h2 id="스트림의-중요성">5.1 스트림의 중요성</h2>
<p>이벤트 기반 플랫폼에서 I/O를 처리하는 가장 효율적인 방법은, 실시간으로 가능한 순간 바로 입력을 사용하고 어플리케이션에서 출력이 생성되는 즉시 내보내는 것이다.</p>
<h3 id="버퍼링-대-스트리밍">버퍼링 대 스트리밍</h3>
<p>fs.readFile 등 거의 모든 비동기 API는 버퍼 모드를 사용한다.<br>
입력 조작의 경우 버퍼 모드는 리소스로부터 오는 모든 데이터를 버퍼에 수집한다.<br>
그리고 자원을 모두 읽어들인 후 콜백에 전달한다.<br>
버퍼의 문제점은, I/O동작이 <strong>완료</strong>될 때 까지 기다려야 한다는 점이다.<br>
반면에 스트림을 사용하면, 리소스에서 도착하자마자 데이터를 처리할 수 있다.<br>
소비자는 이제 모든 데이터가 버퍼에 수집될 때까지 기다리지 않고 즉시 처리할 수 있다.<br>
이 두 방식은 <strong>공간 효율성</strong> 과 <strong>시간 효율성</strong> 에서 차이를 보인다. 또한 <strong>결합성</strong>에서도 차이를 보인다.</p>
<h3 id="공간-효율성">공간 효율성</h3>
<p>스트림은 버퍼처럼 모든 데이터를 한꺼번에 처리하지 않으므로, 버퍼에서는 불가능했던 수백 메가, 혹은 기가바이트의 매우 큰 파일을 읽는 등의 작업도 가능하게 된다.</p>
<h4 id="버퍼링된-api를-사용한-압축">버퍼링된 API를 사용한 압축</h4>
<p>간단한 CLI를 생각해 보자.</p>
<pre><code>const fs = require('fs');
const zlib = require('zlib');
const file = process.argv[2];

fs.readFile(file,(err. buffer) =&gt; {
   zlib.gzib(buffer,(err, buffer)-&gt;{
   	fs.writeFile(file + '.gz', buffer, err=&gt;{
   		console.log('File sucessfully compressed');
   	});
   });
});

##실행
node gzip &lt;filepath&gt;
</code></pre>
<p>V8의 버퍼는 약 1기가이므로, 그것보다 더 큰 파일을 제공하면 오류가 발생한다.</p>
<h4 id="스트림을-사용한-압축">스트림을 사용한 압축</h4>
<p>앞의 예시와 달리, 스트림을 이용하면 크기가 큰 파일도 압축할 수 있다.</p>
<pre><code> const fs = require('fs');
 const zlib = require('zilb');
const file = process.argv[2];

fs.createReadStream(file)
	.pipe(zlib.createGzip())
	.pipe(fs.createWritreStream(file + '.gz'))
	.on('finish', () =&gt; console.log('File successfully compressed'));
</code></pre>
<p>스트림은 성능뿐만 아니라 인터페이스도 좋고, 결합성이 뛰어나다.<br>
따라서 깨끗하고 우아하며 간결한 코드의 작성이 가능하다.</p>
<h3 id="시간-효율성">시간 효율성</h3>
<p>파일을 압축하고 원격 HTTP 서버에 업로드하는 어플리케이션이 있을 때, 원격 HTTP서버는 압축을 풀어 파일 시스템에 저장한다. 이 때 클라이언트가 버퍼링 API를 사용하여 구현하면, 업로드는 전체 파일을 읽어 압축한 경우에만 시작할 수 있다. 똑같은 결과를 얻는 데 더 좋은 방법은 <strong>스트림</strong>을 사용하는 것이다. 클라이언트 시스템에서 스트림을 사용하면, 파일 시스템에서 데이터 덩어리를 읽는 즉시 압측하고 보낼 수 있다.<br>
반면 서버에서는 원격 피어에서 수신된 즉시 모든 덩어리를 압축 해제할 수 있다.</p>
<pre><code># 서버
const http = require('http');
const fs = require('fs');
const zlib = require('zlib');

const server = http.createServer((req,res)=&gt;{
	const filename = req.headers.filename;
	console.log('File request received: " + filename);
req
	.pipe(zlib.createGunzip())
	.pipe(fs.createWriteStream(filename))
	.on('finish',()=&gt;{
		res.writeHead(201, {'Content-Type': 'text/plain'});
		res.end('That's it\n');
		console.log(`File saved: ${filename}`);
	});
});

server.listen(3000,()=&gt;console.log('Listening'));
</code></pre>
<blockquote>
<p>D:\NodeJS\DesignPattern\gzipReceive.js<br>
D:\NodeJS\DesignPattern\gzipSend.js</p>
</blockquote>
<p>앞서 말했듯 버퍼를 사용하면, 데이터가 다 올 때 까지 기다린 다음 압축을 시작한다. 이것은 완전히 순차적이다.</p>
<p>하지만 스트림을 사용하면, 첫 청크가 수신되자마자 조립 라인이 시작된다.<br>
또 놀라운 것은, 다음 청크가 사용 가능한 상태가 되면 조립 라인이 병렬로 시작된다.</p>
<h3 id="결합성">결합성</h3>
<p>위의 예시에서 서로 다른 프로세스 유닛들이 pipe()메소드를 사용하여 어떻게 스트림을 구성하는지에 대해 확인했다.<br>
이는 스트림이 균일한 인터페이스를 가지며, API 측면에서 서로를 이해할 수 있기 때문이다. 유일한 전제 조건은 파이프라인의 다음 스트림이 이전 스트림에 의해 생성되어 전달된 데이터 타입을 지원해야 한다는 것이다.<br>
이 데이터 타입은 바이너리, 텍스트, 또는 객체가 될 수 있다.</p>
<p>이 속성(결합성 - pipe의 메소드가 균일함)의 또 다른 예로 암호화를 살펴보자.<br>
위의 모듈에 다음과 같이 암호화 메소드를 추가한다.</p>
<pre><code>#서버
const crypto = require('crypto');
...
	.pipe(zlib.createGzip())
	.pipe(crypto.createCipher('aes-256-cbc','password'))
	...
</code></pre>
<pre><code>#클라
const crypto = require('crypto');
...
res
	.pipe(crypto.createDecipher('aes-256-cbc','password'))
	...
</code></pre>
<p>우리는 이미 존재하는 파이프라인에 변환 스트림을 끼워 넣어 스트림을 재사용했다. 비슷한 방식으로 다른 스트림을 추가하여 결합할 수 있다.</p>
<p>이 접근법의 주요 방법은 재사용성이지만, 지금까지 제시한 코드에서 알 수 있듯 스트림을 사용하면 더 깨끗하고 모듈화된 코드를 만들 수 있다.<br>
이러한 이유로 스트림은 순수한 I/O를 다루는 것뿐만 아니라 코드를 단순화하고 모듈화하는 수단으로 사용되기도 한다.</p>
<h1 id="스트림-시작히기">5.2 스트림 시작히기</h1>
<h2 id="스트림의-구조">5.2.1 스트림의 구조</h2>
<p>Node.js에서 모든 스트림은 스트림의 코어 모듈에서 사용할 수 있는 네 가지 추상 클래스 중 하나의 구현체이다.</p>
<ul>
<li>stream.Readable</li>
<li>stream.Writeable</li>
<li>stream.Duplex</li>
<li>stream.Transform<br>
각 스트림 클래스는 이벤트 이미터의 인스턴스이기도 하다. 즉 작업이 끝났을 때, 혹은 에러가 발생했을 때 등 여러 유형의 이벤트를 제공한다.</li>
</ul>
<p>또한 자바스크립트의 스트림은 두 가지 모드를 제공한다.</p>
<ul>
<li>바이너리 모드 : 데이터가 버퍼 또는 문자열과 같은 덩어리(chunk) 형태로 스트리밍되는 모드</li>
<li>객체 모드 : 스트리밍 데이터가 일련의 별도 객체들로 취급됨</li>
</ul>
<h2 id="readable-스트림">5.2.2 Readable 스트림</h2>
<p>Readable스트림은 데이터 소스를 나타낸다. 노드에서는 스트림 모듈에서 사용할 수 있는 Readableabstract 클래스를 사용하여 구현된다.</p>
<h3 id="스트림에서-읽기">스트림에서 읽기</h3>
<p>Readable 스트림에서 데이터를 수신하는 방법에는 <em>non-flowing</em>과 <em>flowing</em> 두 가지가 있다.</p>
<h4 id="non-flowing모드">non-flowing모드</h4>
<p>Readable 스트림에서의 읽기의 기본 패턴은 새로운 데이터를 읽을 준비가 되었다는 신호인 readable이벤트에 대해 listener를 등록하는 것이다.<br>
그런 다음 루프에서 내부의 청크를 읽고, 버퍼 또는 스트링 객체를 반환하는 read()메소드를 사용하여 수행할 수 있다.</p>
<pre><code>readable.read([size])
</code></pre>
<p>이 접근 방식을 사용하여 필요할 때 즉시 스트림으로부터 명시적으로 데이터를 가져올 수 있다.</p>
<pre><code>process.stdin
	.on('readable',()=&gt;{
		let chunk;
		console.log('New data available');
		while((chunk = process.stdin.read()) !== null){
			console.log(
				`Chunk read: (${chunk.length}) "${chunk.toString()}"`
			);
		}
	})
	.on('end',() =&gt; process.stdout.wrtie('End of stream'));
</code></pre>
<p>read() 메소드는 Readable 스트림의 내부 버퍼에서 데이터를 읽어들이는 동기 작업이다. 스트림이 바이너리 모드로 동작하고 있는 경우, 기본적으로 반환되는 데이터는 Buffer객체이다.</p>
<p>바이너리 모드로 동작하는 Readable스트림에서 스트림의 <code>setEncodeing(encoding)</code>을 초훌하여 buffer를 대신해서 string을 읽을 수 있다.</p>
<p>데이터는 readable 리스너에서 독점적으로 읽을 수 있다. 리스너는 새로운 데이터가 읽기 가능하게 되는 즉시 호출된다. read() 메소드는 내부 버퍼에 더 이상 사용할 수 있는 데이터가 없을 때 null을 반환한다.<br>
이 경우 다시 읽을 수 있다는 이벤트, 또는 스트림의 끝을 알리는 end이벤트가 발생할 때까지 기다려야 한다.</p>
<p><em>파이프 연산자</em> 를 이용하여, 프로그램을 다른 프로세스와 연결할 수도 있다.<br>
스트리밍 패러다임은 작성된 언어와는 관계없이 프로그램 간의 통신을 할 수 있게 해주는 보편적인 인터페이스이다.</p>
<h4 id="flowing모드">Flowing모드</h4>
<p>스트림으로부터 데이터를 읽는 또 다른 방법은, data 이벤트에 리스너를 등록하는 것이다. 이렇게 리스너를 등록하면, 스트림을 Flowing 모드로 전환한다.<br>
여기서 데이터는 read()를 사용하여 꺼내지 않고, 데이터가 도착하자마자 해당 리스너에 전달된다.</p>
<pre><code>process.stdin  
    .on('data',chunk=&gt;{  
		console.log('New data available');  
	    console.log(  
	        `Chunk read: (${chunk.length}) "${chunk.toString()}"`  
	    );    
	})  
	.on('end',() =&gt; process.stdout.wrtie('End of stream'));
</code></pre>
<p>Flowing모드는 데이터 흐름 제어를 위한 유연성이 떨어진다.</p>
<h3 id="readable-스트림-구현하기">Readable 스트림 구현하기</h3>
<p>stream.Readable의 프로토타입을 상속한 새로운 클래스를 만들어야 한다.<br>
실제 stream은 아래와 같은 특성을 가지는 _read() 메소드의 구현체를 제공해야 한다.</p>
<pre><code>readable._read(size)
</code></pre>
<p>Readable 클래스는 내부적으로 push() 메소드를 사용하여 내부 버퍼를 채우는 _read()메소드를 호출한다.</p>
<pre><code>readable.push(chunk)
</code></pre>
<p><mark>read()는 호출되는 메소드이지만, _read()는 직접 호출해서는 안된다.</mark></p>
<h2 id="writable-스트림">5.2.3 Writable 스트림</h2>
<p>Writable 스트림은 데이터의 목적지를 나타낸다. 노드에서는 stream모듈에서 사용할 수 있는 Writable 추상 클래스를 사용하여 구현한다.</p>
<h3 id="스트림에-쓰기">스트림에 쓰기</h3>
<pre><code>writable.write(chunk,[encodeing],[cb])
</code></pre>
<p>일부 데이터를 밀어내는 작업은 매우 간단하게 write()메소드를 사용한다.</p>
<p>더 이상 기록할 데이터가 없다는 신호를 보낼 때는 end()메소드를 사용한다.</p>
<pre><code>writable.end([chunk], [encoding], [callback])
</code></pre>
<pre><code>"use strict";  
  
const Chance = require('chance');  
const chance = new Chance();  
  
require('http').createServer((req, res) =&gt; {  
    res.writeHead(200, {'Content-Type': 'text/plain'}); //[1]  
  while(chance.bool({likelihood: 95})) {       //[2]  
  res.write(chance.string() + '\n'); //[3]  
  }  
    res.end('\nThe end...\n'); //[4]  
  res.on('finish', () =&gt; console.log('All data was sent')); //[5]  
}).listen(8080, () =&gt; console.log('Listening on http://localhost:8080'));
</code></pre>
<p><mark>res.write()</mark> 메소드가 스트림에 임의의 문자열을 작성한다.</p>
<p>finish 메소드는 모든 데이터가 하위 소켓에 flush될 때 발생한다.</p>
<h3 id="백프레셔">백프레셔</h3>
<p>노드 스트림은 스트림이 소비하는 것보다 더 빠르게 데이터를 쓸 경우 병목 현상이 발생할 수 있다. 이런 일이 발생하지 않도록 내부 버퍼가 highWatermark제한을 초과하면, write()는 false를 반환한다.<br>
버퍼가 비워지면 drain이벤트를 발생시켜 다시 쓰기를 시작해도 좋음을 알린다. 이 매커니즘을 <strong>백프레셔</strong>라고 한다.</p>
<h3 id="writeable-스트림-구현">Writeable 스트림 구현</h3>
<p>stream.Writeable의 프로토타입을 상속받아 _write()함수를 구현하여 새로운 Writeable 스트림을 구현할 수 있다.<br>
<a href="https://github.com/Walkers15/Node.js_Design_Patterns_Second_Edition_Code/blob/master/Chapter05/10_streams_writable_implement/toFileStream.js">예시</a></p>
<h2 id="양방향duplex-스트림">5.2.4 양방향(Duplex) 스트림</h2>
<p>양방향 스트림은 Readable과 Writable이 모두 가능한 스트림이다.<br>
이것은 소켓처럼 데이터 스스와 데이터 목적지를 모두 다루는 항목을 다룰 때 유용하다. 양방향 스트림은 단지 stream.Readable 및 stream.Writable의 메소드를 상속하여 구현한다.<br>
즉 우리는, 데이터를 read() 또는 write() 하거나 readable이나 drain 이벤트를 모두 수신할 수 있다.<br>
사용자 정의 이중 스트림을 생성하려면, _read() 및 _write() 메소드를 구현해야 한다.</p>
<h2 id="transform-스트림">5.2.5 Transform 스트림</h2>
<p>Transform 스트림은 데이터 변환을 처리하도록 설계된 특별한 종류의 이중 스트림이다.<br>
Duplex 스트림에서 읽는 데이터와 쓰는 데이터 사이에는 직접적인 관계가 없다.<br>
하지만, Transfrom 스트림은 Writable 쪽에서 받은 각 데이터들에게 어떤 종류의 변형을 적용한 후에 변형된 데이터들을 Readable쪽에서 사용할 수 있도록 한다.<br>
즉, 읽는 데이터와 쓰는 데이터 사이에 관계를 형성할 수 있다.</p>
<p>Transform 스트림의 인터페이스에는 우선 Duplex Stream과 동일한 인터페이스를 구현한다. 또한 _transform()과 _flush() 메소드를 추가로 작성해야 한다.</p>
<h3 id="transform-스트림-구현">5.2.6 Transform 스트림 구현</h3>
<pre><code> "use strict";  
  
const stream = require('stream');  
const util = require('util');  
  
class ReplaceStream extends stream.Transform {  
    constructor(searchString, replaceString) {  
        super();  
		this.searchString = searchString;  
		this.replaceString = replaceString;  
		this.tailPiece = '';  
	 }  
  
    _transform(chunk, encoding, callback) {  
        const pieces = (this.tailPiece + chunk)         //[1]  
		  .split(this.searchString);  
		const lastPiece = pieces[pieces.length - 1];  
		const tailPieceLen = this.searchString.length - 1;  
  
		this.tailPiece = lastPiece.slice(-tailPieceLen); //[2]  
		pieces[pieces.length - 1] = lastPiece.slice(0,-tailPieceLen);  
  
		this.push(pieces.join(this.replaceString)); //[3]  
		 callback();  
  }  
  
    _flush(callback) {  
        this.push(this.tailPiece);  
		callback();  
  }  
}  
  
module.exports = ReplaceStream;
</code></pre>
<p>stream.Transform 기본 클래스를 확장하여 새로운 클래스를 만든다.<br>
_transform() 메소드에서는  Writable스트림의 _write() 메소드와 거의 동일한 형태를 가지고 있지만, 하위 리소스에 데이터를 쓰는 대신 Readable 스트림의 _read() 메소드에서 한 것과 마찬가지로 push()를 사용하여 <mark>데이터의 내부 버퍼에 푸시한다.</mark> ReplaceStram의 _transfrom() 메소드는 알고리즘 구현의 핵심이다. 치환 가능한 검색 항목에 여러 청크에 분산되어 있을 수 있기 때문이다.</p>
<h3 id="파이프를-통한-스트림-연결">파이프를 통한 스트림 연결</h3>
<p>Node.js 의 스트림은 아래와 같은 형식의 인터페이스를 가지는 Readable 스트림의 pipe() 메소드를 사용하여 서로 연결할 수 있다.</p>
<pre><code>readable.pipe(writable,[options])
</code></pre>
<p>직관적으로 알 수 있듯, pipe()메소드는 readable 스트림에서 만들어진 데이터를 취하여 주어진 write 스트림으로 보내준다. 또한 readable 스트림이 end 이벤트를 전달하면 자동으로 writeable 스트림은 종료된다.<br>
pipe() 메소드는 인자로 전달된 writable 스트림을 반환하므로, 해당 스트림이 Readable까지 가능하다면 연결된 호출을 만들어 낼 수 있다.</p>
<pre><code># replace.js
"use strict";
const ReplaceStream = require('./replaceStream');
process.stdin
	.pipe(new ReplaceStream(process.argv[2], process.argv[3]))
	.pipe(process.stdout);
</code></pre>
<pre><code>echo Hello World! | node replace World Node.js
</code></pre>
<pre><code>Hello Node.js
</code></pre>
<h1 id="스트림을-사용한-비동기-제어-흐름">5.3 스트림을 사용한 비동기 제어 흐름</h1>
<p>스트림은 I/O를 다루는 데 유용할 뿐만 아니라 모든 종류의 데이터를 처리하는 데 사용할 수 있는 세련된 패턴이다.<br>
또한 스트림을 활용하여 비동기식 제어 흐름을 흐름 제어로 전환할 수도 있다.</p>
<h2 id="순차-실행">5.3.1 순차 실행</h2>
<p>기본적으로 스트림은 순차적으로 데이터를 처리하므로, 스트림을 전통적인 콜백 기반의 제어 흐름 패턴의 대안으로 활용할 수 있다.</p>
<blockquote>
<p>concatFiles.js<br>
concat.js</p>
</blockquote>
<p>concatFile() 함수에서 스트림만을 사용하여 비동기 순차 반복을 구현할 수 있었다. 순수 JS로 구현된 경우에는 iterator나 async같은 외부 라이브러리를 사용해야 했지만, 이 방법은 작고 세련됐다.</p>
<h2 id="비순차-병렬-실행">5.3.2 비순차 병렬 실행</h2>
<p>스트림은 각 데이터들을 순차 처리한다.<br>
하지만 때때로 Node.js의 동시성을 최대한 활용하지 못하기 때문에 병목 현상이 있을 수 있다. 모든 데이터 덩어리들에 대해 느린 비동기 작업을 실행해야 하는 경우, 실행을 병렬화하고 전체 프로세스의 속도를 높이는 것이 유리할 수 있다. 물론 이 패턴은 <strong>각각의 데이터 덩어리들이 서로 관계가 없는 경우에만</strong> 작동할 수 있다.</p>
<blockquote>
<p>parallelStream.js</p>
</blockquote>
<pre><code>bind 함수 사용법
경우에 따라 상대적인 자바스크립트의 this라는 객체를 내가 지정한 객체로 고정할 수 있도록 함

function sum(num) {  
    return num + this.num1 + this.num2;  
}  
  
var myObj = {num1:20, num2: 3};  
  
var customSum = sum.bind(myObj);  
  
console.log(customSum(5));

#Result: 28
</code></pre>
<p>ParallelSteam.js 에서 주의할 점은, 이 클래스는 항목들을 받은 순서대로 보존하지 않는다는 것이다.</p>
<h3 id="url-상태-모니터링-어플리케이션의-구현">URL 상태 모니터링 어플리케이션의 구현</h3>
<p>커다란 URL 목록의 상태를 모니터링할 수 있는 간단한 서비스를 만든다고 가정할 떄, ParallelStream 클래스를 사용하면 효율적으로 URL 검사를 실행할 수 있다.</p>
<blockquote>
<p>checkUrls.js</p>
</blockquote>
<h2 id="제한된-비순차-병렬-실행">5.3.3 제한된 비순차 병렬 실행</h2>
<p>수많은 작업을 동시에 실행하려고 할 때, 이를 파이프라인으로 처리할 경우 한번에 많은 병렬 작업을 실행하게 되고, 따라서 어플리케이션의 안정성을 해치고 전체 시스템의 가용성을 떨어뜨리게 된다.<br>
이에 대한 해결 방안은, 병렬 작업의 동시 실행을 제한하는 것이다.</p>
<blockquote>
<p>limitedParallelStream.js</p>
</blockquote>
<p>위 코드와 같이 제한할 경우, 작업을 완료할 떄마다 스트림의 차단을 해제할 저장된 continueCallback()을 호출하여 다음 항목의 처리를 시작한다.</p>
<h3 id="제한된-순차-병렬-실행">제한된 순차 병렬 실행</h3>
<p>청크들이 각 실행 작업에 의해 발생되는 동안 청크들을 <strong>재정렬</strong>하기 위한 버퍼를 사용하면, 순차 병렬 실행을 구현할 수 있다.<br>
이 기술은 너무 기니까, <em>throught2-parallel</em>을 사용해 보자.</p>
<pre><code>#sol_checkUrl.js 수정
const throughParallel = require('through2-parallel');
</code></pre>
<pre><code>출력 순서가 입력과 동일하더라도
비동기 작업은 여전히 병렬로 실행될 수 있으며,
원하는 순서를 나열할 수 있다.
</code></pre>
<h1 id="파이프-패턴">5.4 파이프 패턴</h1>
<p>Node.js의 스트림도 서로 다른 패턴으로 함께 연결(pipe)될 수 있다.<br>
두 개의 다른 스트림의 흐름을 하나로 <strong>병합</strong>하고, 한 스트림을 두 개 이상의 연결들로 <strong>분할</strong>하거나, 조건에 따라 흐름을 리다이렉션 할 수 있다.</p>
<h2 id="스트림-결합combine-하기">5.4.1 스트림 결합(combine) 하기</h2>
<p>전체 파이프라인을 모듈화하고 재사용하기 위해서는.</p>
<ul>
<li>결합한 스트림에 쓸 때는 파이프라인의 첫 번째 스트림에 쓴다</li>
<li>결합된 스트림으로부터 읽을 때는 파이프라인의 마지막 스트림에서 읽는다.</li>
</ul>
<p>결합된 스트림은 보통 이중(Duplex)스트림이며, 첫 번째 스트림을 Writable쪽에 연결하고 마지막 스트림을 Readable쪽에 연결하여 만들어진다.</p>
<p>결합된 스트림은 <strong>파이프라인 내부의 모든 스트림에서 발생하는 모든 오류를 포착해야 한다</strong> 따라서, 적절한 오류 관리를 위해 각 스트림에 오류 리스너를 명시적으로 부작해야 한다.</p>
<p>하지만 결합한 스트림이 실제로 블랙박스라면 파이프라인 중간에 있는 스트림에 접근할 수 없으므로, 결합된 스트림에서 나오는 <strong>모든 에러를 수집</strong>해야 한다.</p>
<p>요약하면 아래와 같다.</p>
<ul>
<li>내부 파이프라인을 숨김으로써 블랙박스화하여 재배포할 수 있다.</li>
<li>에러 리스너를 결합한 스트림 자체 외에 파이프라인에 각 스트림들에 첨부하지 않도록 하여 에러 관리를 간소화한다.</li>
</ul>
<p>보통 multipipe 혹은 combine-stream 패키지를 사용한다.</p>
<h3 id="결합된-스트림-구현하기">결합된 스트림 구현하기</h3>
<pre><code>const zlib = require('zlib');
const crypto = require('crypto');
const combine = require('multipipe');
module.exports.compressAndEncrypt = password =&gt; {
	return combine(
		zlib.createGzip(), crypto.createCipher('aes192', password)
	);
};

module.exports.decryptAndDecompress = password =&gt; {
	return combine(
		crypto.createDecipher('aes192', password), zlib.createGunzip()
	);
};
</code></pre>
<pre><code>#archive.js 프로토타입
const fs = require('fs');  
const compressAndEncryptStream = require('./combinedStreams').compressAndEncrypt;  
  
fs.createReadStream(process.argv[3])  
    .pipe(compressAndEncryptStream(process.argv[2]))  
    .pipe(fs.createWriteStream(process.argv[3] + ".gz.enc"));
    .on('error',err=&gt;{
	    //마지막 스트림에서 발생하는 에러만 처리 가능
	    console.log(err);
	});
</code></pre>
<p>모든 스트림을 하나로 결합하여 위의 에러 캐치 문제를 해결할 수 있다.</p>
<pre><code>const fs = require('fs');  
const compressAndEncryptStream = require('./combinedStreams').compressAndEncrypt;
const combine = require('multipipe');  
combine(  
    fs.createReadStream(process.argv[3])  
    .pipe(compressAndEncryptStream(process.argv[2]))
    .pipe(fs.createWriteStream(process.argv[3] + ".dec"))  
).on('error', err =&gt; {  
    //파이프라인 내의 모든 에러들을 처리  
  console.log(err);  
});
</code></pre>
<h2 id="스트림-포크fork하기">5.4.2 스트림 포크(Fork)하기</h2>
<p>하나의 Readable 스트림을 여러 Writable 스트림으로 연결함으로써 스트림을 포크할 수 있다.</p>
<pre><code>const fs = require('fs');  
const crypto = require('crypto');  
  
const sha1Stream = crypto.createHash('sha1');  
sha1Stream.setEncoding('base64');  
  
const md5Stream = crypto.createHash('md5');  
md5Stream.setEncoding('base64');  
  
const inputFile = process.argv[2];  
const inputStream = fs.createReadStream(inputFile);  
inputStream  
    .pipe(sha1Stream)  
    .pipe(fs.createWriteStream(inputFile + '.sha1'))  
;  
  
inputStream  
    .pipe(md5Stream)  
    .pipe(fs.createWriteStream(inputFile + '.md5'))  
;
</code></pre>
<h2 id="스트림-병합merge-하기">5.4.3 스트림 병합(merge) 하기</h2>
<p>일련의 Readable 스트림을 하나의 Writable 스트림으로 파이프한다.</p>
<pre><code>#mergeTar.js
const tar = require('tar');  
const fstream = require('fstream');  
const path = require('path');  
  
const destination = path.resolve(process.argv[2]);  
const sourceA = path.resolve(process.argv[3]);  
const sourceB = path.resolve(process.argv[4]);  
  
const pack = tar.Pack();  
pack.pipe(fstream.Writer(destination));  
  
let endCount = 0;  
function onEnd() {  
    if(++endCount === 2) {  
        pack.end();  
  }  
}  
  
const sourceStreamA = fstream.Reader({type: "Directory", path: sourceA})  
    .on('end', onEnd)  
;  
  
const sourceStreamB = fstream.Reader({type: "Directory", path: sourceB})  
    .on('end', onEnd)  
;  
  
sourceStreamA.pipe(pack, {end: false});  
sourceStreamB.pipe(pack, {end: false});
</code></pre>
<p>스트림 병합과 포크에 대한 문제점들은 아래와 같다.</p>
<ul>
<li>포크에서 pipe()를 호출할 때, {end:false}를 옵션으로 호출하지 않으면 inputStream이 끝날 때 한쪽 writeStream이 작업을 먼저 끝낼 경우 작업으로 종료될 수 있다.</li>
<li>포크된 두 스트림은 동일한 청크를 수신하기 때문에, 먼저 수정한 데이터에 의해 다른 스트림의 값이 영향을 받을 수 있다.</li>
<li>백프레셔가 바로 발생한다.</li>
<li>병합 패턴에서, 파이프된 데이터가 임의로 섞임</li>
</ul>
<h2 id="멀티플렉싱과-디멀티플렉싱">5.4.4 멀티플렉싱과 디멀티플렉싱</h2>
<p>병합 스트림 패턴의 특별한 변형 패턴이다.<br>
이 패턴에서는 여러 스트림을 함께 결합하지 않고 대신 공유 채널을 사용하여 일련의 스트림 데이터를 전달한다.</p>
<h1 id="요약">5.5 요약</h1>
<p>스트림은 여러개를 동시에 연결할 수 있다.<br>
우리는 기본적인 네 개의 스트림에 대해 구현하는 방법과 상속받아 새로운 스트림을 구현하는 법을 배웠다.<br>
한 개의 스트림으로 작업을 수행할 수 없는 경우에는 다른 스트림을 서로 연결하여 수행할 수 있다.<br>
또한 스트림은 Node.js의 기능을 이해하는 데 도움을 줄 뿐만 아니라, 바이너리 및 문자열, 객체를 처리하는데 중요한 패턴의 필수 요소라는 것을 인지해야 한다.</p>

